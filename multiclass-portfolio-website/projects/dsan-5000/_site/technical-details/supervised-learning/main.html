<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DSAN-5000: Project - Supervised Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/gu-logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">DSAN-5000: Project</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../report/report.html"> 
<span class="menu-text">Report</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-technical-details" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Technical details</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-technical-details">    
        <li>
    <a class="dropdown-item" href="../../technical-details/data-collection/main.html">
 <span class="dropdown-text">Data-collection</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/data-cleaning/main.html">
 <span class="dropdown-text">Data-cleaning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/data-balancing/main.html">
 <span class="dropdown-text">Counterfactual Data Balancing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/eda/main.html">
 <span class="dropdown-text">Exploratory Data Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/unsupervised-learning/main.html">
 <span class="dropdown-text">Unsupervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/supervised-learning/main.html">
 <span class="dropdown-text">Supervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/progress-log.html">
 <span class="dropdown-text">Progress Log</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/llm-usage-log.html">
 <span class="dropdown-text">LLM usage Log</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../bibliography.html"> 
<span class="menu-text">Bibliography</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../appendix.html"> 
<span class="menu-text">Appendix</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/courtneyrgreen/dsan5000_final_project"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://crg123.georgetown.domains/"> 
<span class="menu-text">Back to Portfolio</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-and-motivation" id="toc-introduction-and-motivation" class="nav-link active" data-scroll-target="#introduction-and-motivation">Introduction and Motivation</a></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data Preprocessing</a>
  <ul class="collapse">
  <li><a href="#sample-of-balanced-dataset" id="toc-sample-of-balanced-dataset" class="nav-link" data-scroll-target="#sample-of-balanced-dataset">Sample of Balanced Dataset</a></li>
  <li><a href="#race-distribution-by-exoneration-status" id="toc-race-distribution-by-exoneration-status" class="nav-link" data-scroll-target="#race-distribution-by-exoneration-status">Race Distribution by Exoneration Status</a></li>
  <li><a href="#exoneration-label-mapping" id="toc-exoneration-label-mapping" class="nav-link" data-scroll-target="#exoneration-label-mapping">Exoneration Label Mapping</a></li>
  <li><a href="#one-hot-encoding" id="toc-one-hot-encoding" class="nav-link" data-scroll-target="#one-hot-encoding">One Hot Encoding</a></li>
  </ul></li>
  <li><a href="#training-and-testing-strategy" id="toc-training-and-testing-strategy" class="nav-link" data-scroll-target="#training-and-testing-strategy">Training and Testing Strategy</a></li>
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection">Model Selection</a>
  <ul class="collapse">
  <li><a href="#model-evaluation-metrics" id="toc-model-evaluation-metrics" class="nav-link" data-scroll-target="#model-evaluation-metrics">Model Evaluation Metrics</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#model-performance-summary" id="toc-model-performance-summary" class="nav-link" data-scroll-target="#model-performance-summary">Model Performance Summary</a></li>
  <li><a href="#roc-curve" id="toc-roc-curve" class="nav-link" data-scroll-target="#roc-curve">ROC Curve</a></li>
  <li><a href="#confusion-matrix" id="toc-confusion-matrix" class="nav-link" data-scroll-target="#confusion-matrix">Confusion Matrix</a></li>
  <li><a href="#calibration-curve" id="toc-calibration-curve" class="nav-link" data-scroll-target="#calibration-curve">Calibration Curve</a></li>
  </ul></li>
  <li><a href="#naive-bayes" id="toc-naive-bayes" class="nav-link" data-scroll-target="#naive-bayes">Naive Bayes</a>
  <ul class="collapse">
  <li><a href="#model-performance-summary-1" id="toc-model-performance-summary-1" class="nav-link" data-scroll-target="#model-performance-summary-1">Model Performance Summary</a></li>
  <li><a href="#roc-curve-1" id="toc-roc-curve-1" class="nav-link" data-scroll-target="#roc-curve-1">ROC Curve</a></li>
  <li><a href="#confusion-matrix-1" id="toc-confusion-matrix-1" class="nav-link" data-scroll-target="#confusion-matrix-1">Confusion Matrix</a></li>
  <li><a href="#calibration-curve-1" id="toc-calibration-curve-1" class="nav-link" data-scroll-target="#calibration-curve-1">Calibration Curve</a></li>
  </ul></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random Forest</a>
  <ul class="collapse">
  <li><a href="#model-performance-summary-2" id="toc-model-performance-summary-2" class="nav-link" data-scroll-target="#model-performance-summary-2">Model Performance Summary</a></li>
  <li><a href="#roc-curve-2" id="toc-roc-curve-2" class="nav-link" data-scroll-target="#roc-curve-2">ROC Curve</a></li>
  <li><a href="#feature-importance" id="toc-feature-importance" class="nav-link" data-scroll-target="#feature-importance">Feature Importance</a></li>
  <li><a href="#confusion-matrix-2" id="toc-confusion-matrix-2" class="nav-link" data-scroll-target="#confusion-matrix-2">Confusion Matrix</a></li>
  <li><a href="#calibration-curve-2" id="toc-calibration-curve-2" class="nav-link" data-scroll-target="#calibration-curve-2">Calibration Curve</a></li>
  </ul></li>
  <li><a href="#k-nearest-neighbors-knn" id="toc-k-nearest-neighbors-knn" class="nav-link" data-scroll-target="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a>
  <ul class="collapse">
  <li><a href="#model-performance-summary-3" id="toc-model-performance-summary-3" class="nav-link" data-scroll-target="#model-performance-summary-3">Model Performance Summary</a></li>
  <li><a href="#roc-curve-3" id="toc-roc-curve-3" class="nav-link" data-scroll-target="#roc-curve-3">ROC Curve</a></li>
  <li><a href="#confusion-matrix-3" id="toc-confusion-matrix-3" class="nav-link" data-scroll-target="#confusion-matrix-3">Confusion Matrix</a></li>
  <li><a href="#calibration-curve-3" id="toc-calibration-curve-3" class="nav-link" data-scroll-target="#calibration-curve-3">Calibration Curve</a></li>
  </ul></li>
  <li><a href="#model-comparison" id="toc-model-comparison" class="nav-link" data-scroll-target="#model-comparison">Model Comparison</a>
  <ul class="collapse">
  <li><a href="#why-random-forest" id="toc-why-random-forest" class="nav-link" data-scroll-target="#why-random-forest">Why Random Forest?</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#predicted-probability-with-most-accurate-model" id="toc-predicted-probability-with-most-accurate-model" class="nav-link" data-scroll-target="#predicted-probability-with-most-accurate-model">Predicted Probability with Most Accurate Model</a>
  <ul class="collapse">
  <li><a href="#average-predicted-probability-of-wrongful-conviction-in-illinois-by-race" id="toc-average-predicted-probability-of-wrongful-conviction-in-illinois-by-race" class="nav-link" data-scroll-target="#average-predicted-probability-of-wrongful-conviction-in-illinois-by-race">Average Predicted Probability of Wrongful Conviction in Illinois by Race</a></li>
  <li><a href="#average-predicted-probability-of-wrongful-conviction-in-illinois-by-county" id="toc-average-predicted-probability-of-wrongful-conviction-in-illinois-by-county" class="nav-link" data-scroll-target="#average-predicted-probability-of-wrongful-conviction-in-illinois-by-county">Average Predicted Probability of Wrongful Conviction in Illinois by County</a></li>
  <li><a href="#average-predicted-probability-of-wrongful-conviction-in-illinois-by-race-and-ounty" id="toc-average-predicted-probability-of-wrongful-conviction-in-illinois-by-race-and-ounty" class="nav-link" data-scroll-target="#average-predicted-probability-of-wrongful-conviction-in-illinois-by-race-and-ounty">Average Predicted Probability of Wrongful Conviction in Illinois by Race and ounty</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Supervised Learning</h1>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<section id="introduction-and-motivation" class="level1">
<h1>Introduction and Motivation</h1>
</section>
<section id="data-preprocessing" class="level1">
<h1>Data Preprocessing</h1>
<p>The core of the data preprocessing process took place in the Counterfactual Data Balancing tab, where representative samples were drawn from the Illinois incarcerated population to simulate a comparable group of individuals who were not exonerated. The racial distribution was carefully modeled to reflect the broader incarcerated population, ensuring the simulated group was as representative as possible. This dataset was then merged with the exoneration data to create a final, balanced dataset. By balancing the data in this way,a clean and reliable foundation for building supervised learning models was created to analyze and predict the factors most closely associated with exoneration outcomes.</p>
<section id="sample-of-balanced-dataset" class="level2">
<h2 class="anchored" data-anchor-id="sample-of-balanced-dataset">Sample of Balanced Dataset</h2>
<div id="cell-4" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary Libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, StandardScaler</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, roc_auc_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>exonerees_balanced <span class="op">=</span> pd.read_csv(<span class="st">'../../data/processed-data/exonerees_balanced.csv'</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>exonerees_balanced.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">last_name</th>
<th data-quarto-table-cell-role="th">first_name</th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">state</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">worst_crime_display</th>
<th data-quarto-table-cell-role="th">sentence</th>
<th data-quarto-table-cell-role="th">sentence_in_years</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">witness_tampering_or_misconduct_interrogating_co_defendant</th>
<th data-quarto-table-cell-role="th">misconduct_in_interrogation_of_exoneree</th>
<th data-quarto-table-cell-role="th">perjury_by_official</th>
<th data-quarto-table-cell-role="th">prosecutor_lied_in_court</th>
<th data-quarto-table-cell-role="th">tag_sum</th>
<th data-quarto-table-cell-role="th">geocode_address</th>
<th data-quarto-table-cell-role="th">Race_orig</th>
<th data-quarto-table-cell-role="th">Label</th>
<th data-quarto-table-cell-role="th">County</th>
<th data-quarto-table-cell-role="th">Race</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Abbott</td>
<td>Cinque</td>
<td>19.0</td>
<td>male</td>
<td>Illinois</td>
<td>41.819738</td>
<td>-87.756525</td>
<td>Drug Possession or Sale</td>
<td>Probation</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>7.0</td>
<td>Cook County, Illinois, United States</td>
<td>Black</td>
<td>Exonerated</td>
<td>Cook</td>
<td>Black</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Abernathy</td>
<td>Christopher</td>
<td>17.0</td>
<td>male</td>
<td>Illinois</td>
<td>41.819738</td>
<td>-87.756525</td>
<td>Murder</td>
<td>Life without parole</td>
<td>100.0</td>
<td>...</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>10.0</td>
<td>Cook County, Illinois, United States</td>
<td>White</td>
<td>Exonerated</td>
<td>Cook</td>
<td>White</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Abrego</td>
<td>Eruby</td>
<td>20.0</td>
<td>male</td>
<td>Illinois</td>
<td>41.819738</td>
<td>-87.756525</td>
<td>Murder</td>
<td>90 years</td>
<td>90.0</td>
<td>...</td>
<td>1.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>9.0</td>
<td>Cook County, Illinois, United States</td>
<td>Hispanic</td>
<td>Exonerated</td>
<td>Cook</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Adams</td>
<td>Demetris</td>
<td>22.0</td>
<td>male</td>
<td>Illinois</td>
<td>41.819738</td>
<td>-87.756525</td>
<td>Drug Possession or Sale</td>
<td>1 year</td>
<td>1.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>7.0</td>
<td>Cook County, Illinois, United States</td>
<td>Black</td>
<td>Exonerated</td>
<td>Cook</td>
<td>Black</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Adams</td>
<td>Kenneth</td>
<td>22.0</td>
<td>male</td>
<td>Illinois</td>
<td>41.819738</td>
<td>-87.756525</td>
<td>Murder</td>
<td>75 years</td>
<td>75.0</td>
<td>...</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>11.0</td>
<td>Cook County, Illinois, United States</td>
<td>Black</td>
<td>Exonerated</td>
<td>Cook</td>
<td>Black</td>
</tr>
</tbody>
</table>

<p>5 rows × 51 columns</p>
</div>
</div>
</div>
</section>
<section id="race-distribution-by-exoneration-status" class="level2">
<h2 class="anchored" data-anchor-id="race-distribution-by-exoneration-status">Race Distribution by Exoneration Status</h2>
<p>A crosstabulation was conducted to analyze the distribution of race between exonerated and non-exonerated individuals within the balanced dataset. Using the <code>pd.crosstab()</code> function, the proportion of each racial category across the two groups was calculated:</p>
<ul>
<li><strong>Exonerated</strong> individuals: those who were wrongfully convicted and later cleared.<br>
</li>
<li><strong>Non-Exonerated</strong> individuals: a simulated group drawn from the broader incarcerated population.</li>
</ul>
<p>By normalizing the values, the crosstab presents the relative frequency of each racial category within both groups. This allows us to pinpoint patterns or disparities in the racial composition of exonerated individuals compared to the simulated non-exonerated group.</p>
<div id="cell-6" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>pd.crosstab(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    exonerees_balanced[<span class="st">'Label'</span>], exonerees_balanced[<span class="st">'Race'</span>],</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    margins<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    normalize<span class="op">=</span><span class="va">True</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Race</th>
<th data-quarto-table-cell-role="th">Black</th>
<th data-quarto-table-cell-role="th">Latino</th>
<th data-quarto-table-cell-role="th">Other</th>
<th data-quarto-table-cell-role="th">White</th>
<th data-quarto-table-cell-role="th">All</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">Label</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Exonerated</td>
<td>0.412636</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046397</td>
<td>0.459033</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Non-Exonerated</td>
<td>0.287266</td>
<td>0.090819</td>
<td>0.004936</td>
<td>0.157947</td>
<td>0.540967</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">All</td>
<td>0.699901</td>
<td>0.090819</td>
<td>0.004936</td>
<td>0.204344</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ul>
<li><strong>Exonerated Group</strong>: The majority are Black (41.2%) and White (4.6%), with no representation for Latino or Other races.<br>
</li>
<li><strong>Non-Exonerated Group</strong>: The racial distribution includes 28.7% Black, 9.1% Latino, 0.5% Other, and 15.8% White.<br>
</li>
<li><strong>Overall</strong>: The total racial distribution reflects the balanced nature of the dataset, with 69.9% Black, 9.1% Latino, and smaller proportions for Other and White categories.</li>
</ul>
<p>This breakdown provides an overview of how race is distributed within the dataset, ensuring transparency in the balancing process and highlighting any disparities between the two groups.</p>
</section>
<section id="exoneration-label-mapping" class="level2">
<h2 class="anchored" data-anchor-id="exoneration-label-mapping">Exoneration Label Mapping</h2>
<p>In this step, the labels identifying whether an individual was exonerated or not were converted into a binary format to prepare the dataset for supervised learning. The <code>Label</code> column was mapped as follows:<br>
- <code>'Exonerated'</code> → <code>1</code><br>
- <code>'Non-Exonerated'</code> → <code>0</code></p>
<p>For clarity and consistency, the column was renamed <strong>“Exonerated”</strong>, making it easier to interpret the target variable during modeling. To streamline the dataset for further processing, only the relevant features were retained: <strong>Race</strong>, <strong>County</strong>, and the newly mapped <strong>Exonerated</strong> column.</p>
<p>A quick preview of the transformed data confirmed the changes, showing the updated binary labels alongside the selected features. This clean, focused dataset will serve as the foundation for building machine learning models in the next steps.</p>
<div id="cell-9" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Map 'Exonerated' to 1 and 'Non-Exonerated' to 0</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>exonerees_balanced[<span class="st">'Label'</span>] <span class="op">=</span> exonerees_balanced[<span class="st">'Label'</span>].<span class="bu">map</span>({<span class="st">'Exonerated'</span>: <span class="dv">1</span>, <span class="st">'Non-Exonerated'</span>: <span class="dv">0</span>})</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename the column to 'exonerated'</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>exonerees_balanced.rename(columns<span class="op">=</span>{<span class="st">'Label'</span>: <span class="st">'Exonerated'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep relevant features</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> exonerees_balanced[[<span class="st">'Race'</span>, <span class="st">'County'</span>, <span class="st">'Exonerated'</span>]].copy()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview the transformed data</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data.head())</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Race County  Exonerated
0  Black   Cook           1
1  White   Cook           1
2    NaN   Cook           1
3  Black   Cook           1
4  Black   Cook           1</code></pre>
</div>
</div>
</section>
<section id="one-hot-encoding" class="level2">
<h2 class="anchored" data-anchor-id="one-hot-encoding">One Hot Encoding</h2>
<p>One hot encoding was applied to convert the categorical features <strong>“Race”</strong> and <strong>“County”</strong> into a numerical format suitable for machine learning models. Since algorithms like logistic regression and other supervised models require numerical inputs, this transformation ensures these features can be effectively incorporated during training.</p>
<p>Each unique value in the <strong>“Race”</strong> and <strong>“County”</strong> columns was transformed into its own binary column, where a value of <code>1</code> indicates the presence of a specific category, and <code>0</code> indicates its absence. To avoid any loss of information, all categories were retained during the encoding process.</p>
<p>Once encoded, the original <strong>“Race”</strong> and <strong>“County”</strong> columns were dropped and replaced with their respective binary columns. This transformation resulted in a dataset with <strong>64 columns</strong>, including the binary target variable <strong>“Exonerated”</strong>. The final dataset is now fully numeric, clean, and well-structured for training supervised learning models.</p>
<div id="cell-11" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform one-hot encoding without dropping any category</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(sparse_output<span class="op">=</span><span class="va">False</span>)  <span class="co"># Use sparse_output instead of sparse</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>encoded_features <span class="op">=</span> encoder.fit_transform(data[[<span class="st">'Race'</span>, <span class="st">'County'</span>]])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame for the encoded features</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>encoded_df <span class="op">=</span> pd.DataFrame(encoded_features, columns<span class="op">=</span>encoder.get_feature_names_out([<span class="st">'Race'</span>, <span class="st">'County'</span>]))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate encoded features with the original dataset</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.concat([data.drop(columns<span class="op">=</span>[<span class="st">'Race'</span>, <span class="st">'County'</span>]), encoded_df], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview the data</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>data.head()</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Exonerated</th>
<th data-quarto-table-cell-role="th">Race_Black</th>
<th data-quarto-table-cell-role="th">Race_Latino</th>
<th data-quarto-table-cell-role="th">Race_Other</th>
<th data-quarto-table-cell-role="th">Race_White</th>
<th data-quarto-table-cell-role="th">Race_nan</th>
<th data-quarto-table-cell-role="th">County_Adams</th>
<th data-quarto-table-cell-role="th">County_Bond</th>
<th data-quarto-table-cell-role="th">County_Boone</th>
<th data-quarto-table-cell-role="th">County_Brown</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">County_Sangamon</th>
<th data-quarto-table-cell-role="th">County_St. Clair</th>
<th data-quarto-table-cell-role="th">County_Stephenson</th>
<th data-quarto-table-cell-role="th">County_Tazewell</th>
<th data-quarto-table-cell-role="th">County_Vermilion</th>
<th data-quarto-table-cell-role="th">County_Washington</th>
<th data-quarto-table-cell-role="th">County_Will</th>
<th data-quarto-table-cell-role="th">County_Williamson</th>
<th data-quarto-table-cell-role="th">County_Winnebago</th>
<th data-quarto-table-cell-role="th">County_Woodford</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>

<p>5 rows × 63 columns</p>
</div>
</div>
</div>
</section>
</section>
<section id="training-and-testing-strategy" class="level1">
<h1>Training and Testing Strategy</h1>
<p>In this step, the dataset was split into training and testing sets to evaluate the performance of the supervised learning models. The <strong>train-test split</strong> method from <code>sklearn.model_selection</code> was used to create a clear separation between the data used to train the model and the data reserved for testing its performance.</p>
<p>An <strong>80-20 split</strong> was implemented, with 80% of the data (876 samples) designated for training and the remaining 20% (220 samples) held out for testing. The 80-20 ratio is a widely accepted standard in machine learning, striking a balance between providing the model with enough data to learn patterns effectively and retaining sufficient unseen data to evaluate its generalization performance. The larger training portion gives the model ample opportunity to identify relationships in the data, while the smaller test set ensures a reliable measure of accuracy and consistency.</p>
<p>To keep the results reproducible, a <strong>random seed</strong> (<code>random_state=42</code>) was applied, ensuring that the split remains consistent across multiple runs. This approach establishes a strong foundation for training and testing the supervised learning models, minimizing the risk of overfitting while still allowing for robust performance evaluation.</p>
<div id="cell-13" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features (X) and target (y)</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.drop(columns<span class="op">=</span>[<span class="st">'Exonerated'</span>])  <span class="co"># Drop the target column</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">'Exonerated'</span>]  <span class="co"># Target column</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into train and test sets (80-20 split)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the shapes of the splits</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set shape:"</span>, X_train.shape)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test set shape:"</span>, X_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training set shape: (876, 62)
Test set shape: (220, 62)</code></pre>
</div>
</div>
</section>
<section id="model-selection" class="level1">
<h1>Model Selection</h1>
<p>To predict the factors associated with exoneration, several supervised learning algorithms were selected: <strong>Logistic Regression</strong>, <strong>Naive Bayes</strong>, <strong>Random Forest</strong>, and <strong>K-Nearest Neighbors (KNN)</strong>. These models were chosen for their balance of simplicity, interpretability, and effectiveness in solving binary classification problems. Each algorithm offers distinct advantages, allowing for a thorough comparison of predictive performance across models.</p>
<section id="model-evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-metrics">Model Evaluation Metrics</h3>
<p>The performance of each model was evaluated using key <strong>binary classification metrics</strong> to ensure a comprehensive assessment:</p>
<ul>
<li><strong>Accuracy</strong>: Measures the overall correctness of the model’s predictions.<br>
</li>
<li><strong>Precision</strong>: Assesses the proportion of predicted positives that were actually correct.<br>
</li>
<li><strong>Recall</strong>: Measures the model’s ability to identify all positive cases.<br>
</li>
<li><strong>F1 Score</strong>: A balanced measure that combines Precision and Recall into a single score.<br>
</li>
<li><strong>ROC-AUC</strong>: Evaluates the model’s capability to distinguish between positive and negative classes.</li>
</ul>
<p>To complement these metrics, the following visualizations were utilized for deeper interpretation:</p>
<ul>
<li><strong>ROC Curve</strong>: Shows the trade-off between True Positive Rate and False Positive Rate at various thresholds, offering insights into classification performance.<br>
</li>
<li><strong>Confusion Matrix</strong>: Breaks down predictions into True Positives, True Negatives, False Positives, and False Negatives to summarize performance.<br>
</li>
<li><strong>Calibration Curve</strong>: Measures how well the predicted probabilities align with actual outcomes, identifying whether the model is overconfident or underconfident.</li>
</ul>
</section>
<section id="results" class="level3">
<h3 class="anchored" data-anchor-id="results">Results</h3>
<p>A <strong>Model Performance Summary</strong> was compiled for each algorithm, including core metrics such as Accuracy, Precision, Recall, F1 Score, and ROC-AUC. Visual aids like <strong>ROC Curves</strong>, <strong>Confusion Matrices</strong>, and <strong>Calibration Curves</strong> were included to validate and interpret model behavior effectively. This comprehensive approach ensures that each model’s performance and reliability are fully evaluated.</p>
</section>
<section id="logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h2>
<p>Logistic Regression was selected as the baseline model due to its simplicity, efficiency, and strong interpretability. As a linear model, it is particularly well-suited for binary classification tasks, such as predicting whether an individual is exonerated (<code>1</code>) or not (<code>0</code>). Logistic Regression estimates the probability of class membership, offering clear insights into the relationship between the input features and the target variable.</p>
<p>A key advantage of Logistic Regression is its assumption of a linear relationship between the independent variables and the log-odds of the outcome. This assumption works effectively when the dataset is well-preprocessed and balanced, as is the case here.</p>
<p>By serving as the benchmark model, Logistic Regression provides a baseline for performance comparison. This allows for a clear evaluation of whether more complex models, such as <strong>Random Forest</strong> or <strong>KNN</strong>, can achieve improved predictive accuracy in exchange for additional computational complexity.</p>
<section id="model-performance-summary" class="level3">
<h3 class="anchored" data-anchor-id="model-performance-summary">Model Performance Summary</h3>
<div id="cell-16" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.calibration <span class="im">import</span> calibration_curve</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic Regression Model</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>log_model <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>log_model.fit(X_train, y_train)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions and Probabilities</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>log_y_pred <span class="op">=</span> log_model.predict(X_test)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>log_y_pred_proba <span class="op">=</span> log_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation Metrics</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>log_accuracy <span class="op">=</span> accuracy_score(y_test, log_y_pred)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>log_precision <span class="op">=</span> precision_score(y_test, log_y_pred)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>log_recall <span class="op">=</span> recall_score(y_test, log_y_pred)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>log_f1 <span class="op">=</span> f1_score(y_test, log_y_pred)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>log_roc_auc <span class="op">=</span> roc_auc_score(y_test, log_y_pred_proba)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Logistic Regression - Accuracy: </span><span class="sc">{</span>log_accuracy<span class="sc">:.2f}</span><span class="ss">, Precision: </span><span class="sc">{</span>log_precision<span class="sc">:.2f}</span><span class="ss">, Recall: </span><span class="sc">{</span>log_recall<span class="sc">:.2f}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>log_f1<span class="sc">:.2f}</span><span class="ss">, ROC-AUC: </span><span class="sc">{</span>log_roc_auc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Logistic Regression - Accuracy: 0.89, Precision: 0.90, Recall: 0.88, F1 Score: 0.89, ROC-AUC: 0.95</code></pre>
</div>
</div>
<p>The <strong>Logistic Regression</strong> model delivered strong performance across all evaluation metrics. An <strong>accuracy</strong> of 0.89 indicates that the model correctly predicted exoneration outcomes 89% of the time. The <strong>precision</strong> score of 0.90 shows that 90% of the individuals predicted as exonerated were truly exonerated, highlighting the model’s ability to minimize false positives. Similarly, the <strong>recall</strong> of 0.88 demonstrates that the model successfully identified 88% of all actual exonerated cases, proving its effectiveness at capturing true positives.</p>
<p>The <strong>F1 Score</strong>, which balances precision and recall, came in at 0.89, confirming strong overall classification performance. Finally, the <strong>ROC-AUC score</strong> of 0.95 reflects the model’s exceptional ability to distinguish between exonerated and non-exonerated individuals across different probability thresholds. A score this high indicates that the model is highly effective at separating the two classes with minimal overlap in predictions.</p>
<p>These results underscore that Logistic Regression serves as a reliable and high-performing baseline model for predicting exoneration outcomes.</p>
</section>
<section id="roc-curve" class="level3">
<h3 class="anchored" data-anchor-id="roc-curve">ROC Curve</h3>
<div id="cell-19" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC Curve</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, log_y_pred_proba)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="ss">f"Logistic Regression ROC Curve (AUC = </span><span class="sc">{</span>log_roc_auc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Logistic Regression ROC Curve"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>ROC Curve’s</strong> steep rise toward the top-left corner indicates strong performance in distinguishing between exonerated and non-exonerated individuals. The <strong>AUC (Area Under the Curve)</strong> value of <strong>0.95</strong> confirms the model’s exceptional discriminatory power. While a perfect model achieves an AUC of 1.0 and a random classifier yields an AUC of 0.5 (represented by the dashed diagonal line), the high AUC score here demonstrates that the Logistic Regression model is highly effective at separating the two classes with minimal false classifications. This ROC curve, combined with the corresponding AUC score, highlights the model’s efficient performance and reliability in predicting exoneration outcomes.</p>
</section>
<section id="confusion-matrix" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix">Confusion Matrix</h3>
<div id="cell-22" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Confusion Matrix</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(log_model, X_test, y_test)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix - Logistic Regression"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Confusion Matrix</strong> for the Logistic Regression model provides a clear breakdown of predictions against actual outcomes, highlighting the following results:</p>
<ul>
<li><strong>True Negatives (Top-Left)</strong>: 96 cases were correctly classified as non-exonerated.<br>
</li>
<li><strong>False Positives (Top-Right)</strong>: 11 cases were incorrectly predicted as exonerated.<br>
</li>
<li><strong>False Negatives (Bottom-Left)</strong>: 14 cases were incorrectly classified as non-exonerated.<br>
</li>
<li><strong>True Positives (Bottom-Right)</strong>: 99 cases were correctly identified as exonerated.</li>
</ul>
<p>The model demonstrates strong predictive accuracy, with a high count of true positives and true negatives. While the false positive and false negative rates are relatively low, they still pinpoint areas that could benefit from further refinement. Specifically, the <strong>14 false negatives</strong> reflect cases where the model failed to identify individuals who were exonerated, a critical consideration for future adjustments. On the other hand, the <strong>11 false positives</strong> represent instances where exoneration was incorrectly predicted, signaling a slight overreach in classification.</p>
</section>
<section id="calibration-curve" class="level3">
<h3 class="anchored" data-anchor-id="calibration-curve">Calibration Curve</h3>
<div id="cell-25" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Calibration Curve</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>prob_true, prob_pred <span class="op">=</span> calibration_curve(y_test, log_y_pred_proba, n_bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.plot(prob_pred, prob_true, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">"Logistic Regression"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>, label<span class="op">=</span><span class="st">"Perfect Calibration"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Mean Predicted Probability"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Fraction of Positives"</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Calibration Curve - Logistic Regression"</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Calibration Curve</strong> reveals that the model’s predictions are generally well-calibrated but show slight deviations, particularly at the extremes:</p>
<ul>
<li>At lower probabilities (<strong>0.0 to 0.2</strong>), the model underestimates the actual fraction of positives, indicating a conservative bias in this range.<br>
</li>
<li>For mid-range probabilities (<strong>0.4 to 0.6</strong>), the predictions align closely with the observed outcomes, reflecting strong calibration in this critical range.<br>
</li>
<li>At higher probabilities (<strong>0.8 to 1.0</strong>), the model slightly overestimates, as the fraction of positives reaches 1.0 earlier than the ideal calibration line.</li>
</ul>
<p>These results suggest that while the model performs reliably across the mid-to-high probability ranges, minor misalignments occur at the extremes. These deviations highlight areas where additional tuning or recalibration could further improve probability estimates. Despite this, the overall calibration remains strong, confirming the model’s effectiveness in producing meaningful and interpretable probability scores for predicting exoneration outcomes.</p>
</section>
</section>
<section id="naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="naive-bayes">Naive Bayes</h2>
<section id="model-performance-summary-1" class="level3">
<h3 class="anchored" data-anchor-id="model-performance-summary-1">Model Performance Summary</h3>
<div id="cell-29" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Naive Bayes Model</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>nb_model <span class="op">=</span> GaussianNB()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>nb_model.fit(X_train, y_train)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions and Probabilities</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>nb_y_pred <span class="op">=</span> nb_model.predict(X_test)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>nb_y_pred_proba <span class="op">=</span> nb_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation Metrics</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>nb_accuracy <span class="op">=</span> accuracy_score(y_test, nb_y_pred)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>nb_precision <span class="op">=</span> precision_score(y_test, nb_y_pred)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>nb_recall <span class="op">=</span> recall_score(y_test, nb_y_pred)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>nb_f1 <span class="op">=</span> f1_score(y_test, nb_y_pred)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>nb_roc_auc <span class="op">=</span> roc_auc_score(y_test, nb_y_pred_proba)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Naive Bayes - Accuracy: </span><span class="sc">{</span>nb_accuracy<span class="sc">:.2f}</span><span class="ss">, Precision: </span><span class="sc">{</span>nb_precision<span class="sc">:.2f}</span><span class="ss">, Recall: </span><span class="sc">{</span>nb_recall<span class="sc">:.2f}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>nb_f1<span class="sc">:.2f}</span><span class="ss">, ROC-AUC: </span><span class="sc">{</span>nb_roc_auc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Naive Bayes - Accuracy: 0.83, Precision: 0.75, Recall: 0.99, F1 Score: 0.85, ROC-AUC: 0.86</code></pre>
</div>
</div>
<p>The <strong>Naive Bayes</strong> model achieved an <strong>accuracy</strong> of 0.83, meaning it correctly predicted 83% of the outcomes. A key highlight is the <strong>recall</strong> score of <strong>0.99</strong>, demonstrating the model’s exceptional ability to identify actual positives (exonerated individuals) while minimizing false negatives. This makes Naive Bayes particularly advantageous in scenarios where capturing all exoneration cases is critical. However, the <strong>precision</strong> score of <strong>0.75</strong> reveals that 25% of the predicted positives were incorrect, pointing to a higher rate of false positives. The <strong>F1 Score</strong>, which strikes a balance between precision and recall, is <strong>0.85</strong>, indicating solid overall performance despite the trade-off in precision. Additionally, the <strong>ROC-AUC score</strong> of <strong>0.86</strong> confirms that the model effectively differentiates between exonerated and non-exonerated individuals, though it falls slightly short of the performance achieved by Logistic Regression. These results highlight that Naive Bayes prioritizes recall—ensuring most true positives are captured—at the expense of precision. This trade-off makes the model particularly useful in applications where minimizing missed exonerations outweighs the cost of false positives.</p>
</section>
<section id="roc-curve-1" class="level3">
<h3 class="anchored" data-anchor-id="roc-curve-1">ROC Curve</h3>
<div id="cell-32" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC Curve</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, nb_y_pred_proba)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="ss">f"Naive Bayes ROC Curve (AUC = </span><span class="sc">{</span>nb_roc_auc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Naive Bayes ROC Curve"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>ROC Curve</strong> demonstrates that the Naive Bayes model effectively distinguishes between exonerated and non-exonerated individuals, rising steeply toward the top-left corner. The <strong>AUC (Area Under the Curve)</strong> value of <strong>0.86</strong> confirms strong overall performance, reflecting the model’s ability to separate the two classes. That said, the slightly lower AUC compared to Logistic Regression suggests that Naive Bayes is less precise when ranking positive predictions. This aligns with its earlier results, where high recall (capturing nearly all true positives) came at the cost of lower precision. The shape of the curve further reveals that while the model achieves excellent sensitivity, it is more prone to false positives at certain thresholds. Ultimately, the Naive Bayes ROC curve highlights the model’s strength in identifying exonerated individuals, reinforcing its reliability for scenarios where capturing true positives is prioritized over reducing false positives.</p>
</section>
<section id="confusion-matrix-1" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-1">Confusion Matrix</h3>
<div id="cell-35" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Confusion Matrix</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(nb_model, X_test, y_test)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix - Logistic Regression"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Confusion Matrix</strong> for the Logistic Regression model provides a detailed breakdown of its performance in predicting exoneration outcomes. The matrix shows the following:</p>
<ul>
<li><strong>True Negatives (Top-Left)</strong>: 70 instances were correctly classified as non-exonerated.<br>
</li>
<li><strong>False Positives (Top-Right)</strong>: 37 instances were incorrectly predicted as exonerated.<br>
</li>
<li><strong>False Negatives (Bottom-Left)</strong>: Only 1 instance was incorrectly classified as non-exonerated.<br>
</li>
<li><strong>True Positives (Bottom-Right)</strong>: 112 instances were correctly classified as exonerated.</li>
</ul>
<p>The matrix reveals that the model is highly effective at identifying <strong>true positives</strong> (exonerated individuals), with only 1 false negative, which aligns with its strong <strong>recall</strong> score. However, the relatively high number of <strong>false positives</strong> (37) suggests that the model tends to overpredict exoneration, which slightly impacts precision.</p>
<p>Overall, while the Logistic Regression model demonstrates strong performance in identifying exonerated individuals, the false positives indicate room for improvement in reducing misclassifications of non-exonerated cases.</p>
</section>
<section id="calibration-curve-1" class="level3">
<h3 class="anchored" data-anchor-id="calibration-curve-1">Calibration Curve</h3>
<div id="cell-38" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Calibration Curve</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>prob_true, prob_pred <span class="op">=</span> calibration_curve(y_test, nb_y_pred_proba, n_bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.plot(prob_pred, prob_true, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">"Logistic Regression"</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>, label<span class="op">=</span><span class="st">"Perfect Calibration"</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Mean Predicted Probability"</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Fraction of Positives"</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Calibration Curve - Naive Bayes"</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Calibration Curve</strong> reveals a clear pattern of <strong>underconfidence</strong>, where the predicted probabilities are consistently lower than the actual fraction of positives. Even at higher predicted probabilities (close to 1.0), the model underestimates the true proportion of positive outcomes, failing to align with the perfect calibration line. This behavior is a known limitation of Naive Bayes models, stemming from their strong assumption of feature independence. While this assumption enables efficient performance and strong recall, it often leads to poorly calibrated probability estimates, as seen here where the model identifies positive cases effectively but struggles to assign probabilities that accurately reflect confidence in predictions.</p>
</section>
</section>
<section id="random-forest" class="level2">
<h2 class="anchored" data-anchor-id="random-forest">Random Forest</h2>
<section id="model-performance-summary-2" class="level3">
<h3 class="anchored" data-anchor-id="model-performance-summary-2">Model Performance Summary</h3>
<div id="cell-42" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Model</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions and Probabilities</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>rf_y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>rf_y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation Metrics</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>rf_accuracy <span class="op">=</span> accuracy_score(y_test, rf_y_pred)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>rf_precision <span class="op">=</span> precision_score(y_test, rf_y_pred)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>rf_recall <span class="op">=</span> recall_score(y_test, rf_y_pred)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>rf_f1 <span class="op">=</span> f1_score(y_test, rf_y_pred)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>rf_roc_auc <span class="op">=</span> roc_auc_score(y_test, rf_y_pred_proba)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random Forest - Accuracy: </span><span class="sc">{</span>rf_accuracy<span class="sc">:.2f}</span><span class="ss">, Precision: </span><span class="sc">{</span>rf_precision<span class="sc">:.2f}</span><span class="ss">, Recall: </span><span class="sc">{</span>rf_recall<span class="sc">:.2f}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>rf_f1<span class="sc">:.2f}</span><span class="ss">, ROC-AUC: </span><span class="sc">{</span>rf_roc_auc<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest - Accuracy: 0.89, Precision: 0.89, Recall: 0.89, F1 Score: 0.89, ROC-AUC: 0.95</code></pre>
</div>
</div>
<p>The <strong>Random Forest</strong> model delivers outstanding performance across all evaluation metrics, achieving an <strong>accuracy</strong> of 0.89, meaning 89% of the predictions were correct. Both the <strong>precision</strong> and <strong>recall</strong> scores stand at <strong>0.89</strong>, reflecting the model’s strong ability to balance minimizing false positives while correctly identifying true positives. This balance underscores its effectiveness in accurately predicting exoneration outcomes. The <strong>F1 Score</strong>, also <strong>0.89</strong>, reinforces the model’s consistency by combining precision and recall into a single, reliable measure. Additionally, the <strong>ROC-AUC score</strong> of <strong>0.95</strong> demonstrates the model’s exceptional ability to differentiate between exonerated and non-exonerated individuals. This performance aligns closely with that of Logistic Regression, further validating the model’s robustness. Altogether, the Random Forest model provides a well-rounded and reliable classification solution, balancing precision, recall, and accuracy effectively. Its strong performance across all key metrics makes it a highly capable candidate for predicting exoneration outcomes.</p>
</section>
<section id="roc-curve-2" class="level3">
<h3 class="anchored" data-anchor-id="roc-curve-2">ROC Curve</h3>
<div id="cell-45" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC Curve</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, rf_y_pred_proba)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="ss">f"Random Forest ROC Curve (AUC = </span><span class="sc">{</span>rf_roc_auc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Random Forest ROC Curve"</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The visual representation of the <strong>ROC Curve</strong> reinforces the model’s <strong>AUC (Area Under the Curve)</strong> value of <strong>0.95</strong>, showcasing its excellent discriminatory power. The model consistently achieves a high True Positive Rate while maintaining a low False Positive Rate. This aligns closely with previously reported metrics—accuracy, precision, and recall—further validating the model’s reliability. The curve’s steep rise and near-flat progression highlight Random Forest’s ability to deliver both high sensitivity and specificity, effectively identifying positive cases while minimizing false positives. This strong performance positions Random Forest as a robust and dependable model for predicting exoneration outcomes.</p>
</section>
<section id="feature-importance" class="level3">
<h3 class="anchored" data-anchor-id="feature-importance">Feature Importance</h3>
<div id="cell-48" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Importance</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> pd.Series(rf_model.feature_importances_, index<span class="op">=</span>X.columns).sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>feature_importances.plot(kind<span class="op">=</span><span class="st">'bar'</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>), title<span class="op">=</span><span class="st">"Feature Importance"</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Feature Importance</strong> plot for the Random Forest model provides insight into which features had the greatest influence on the model’s predictions. Random Forest calculates feature importance by evaluating how much each feature reduces impurity (e.g., Gini index) across all decision trees within the ensemble. This approach makes Random Forest particularly effective for understanding the relative impact of individual predictors. The plot shows that <strong>“County_Cook”</strong> stands out as the most influential feature by a significant margin, followed closely by <strong>race-related variables</strong> such as <strong>“Race_Black”</strong> and <strong>“Race_White”</strong>. The remaining features, including other counties, contribute far less to the model’s decision-making process, displaying diminishing importance.</p>
<p>Feature importance was calculated exclusively for the Random Forest model, as its tree-based structure is inherently designed to measure and interpret feature contributions. By contrast, models like Naive Bayes do not provide native feature importance measures due to their reliance on probabilistic assumptions rather than iterative splits within the feature space. The feature importance plot underscores the dominant role of geographic location (e.g., <strong>“County_Cook”</strong>) and race in predicting exoneration outcomes, offering a clearer understanding of the factors driving the model’s predictions and highlight key areas for further investigation.</p>
</section>
<section id="confusion-matrix-2" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-2">Confusion Matrix</h3>
<div id="cell-51" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Confusion Matrix</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix - Logistic Regression"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Confusion Matrix</strong> for the Random Forest model provides a clear evaluation of its classification performance:</p>
<ul>
<li><strong>True Negatives (Top-Left)</strong>: 95 cases were correctly classified as non-exonerated.<br>
</li>
<li><strong>False Positives (Top-Right)</strong>: 12 cases were incorrectly predicted as exonerated.<br>
</li>
<li><strong>False Negatives (Bottom-Left)</strong>: 12 cases were incorrectly classified as non-exonerated.<br>
</li>
<li><strong>True Positives (Bottom-Right)</strong>: 101 cases were correctly identified as exonerated.</li>
</ul>
<p>The results demonstrate that the Random Forest model effectively balances true positives and true negatives, with a relatively low number of misclassifications. That said, the presence of <strong>12 false positives</strong> and <strong>12 false negatives</strong> highlights areas where the model could benefit from further refinement. These findings align closely with the model’s reported metrics, particularly its <strong>high accuracy and recall</strong>, reinforcing the model’s overall reliability in predicting exoneration outcomes.</p>
</section>
<section id="calibration-curve-2" class="level3">
<h3 class="anchored" data-anchor-id="calibration-curve-2">Calibration Curve</h3>
<div id="cell-54" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Calibration Curve</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>prob_true, prob_pred <span class="op">=</span> calibration_curve(y_test, rf_y_pred_proba, n_bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>plt.plot(prob_pred, prob_true, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">"Logistic Regression"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>, label<span class="op">=</span><span class="st">"Perfect Calibration"</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Mean Predicted Probability"</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Fraction of Positives"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Calibration Curve - Logistic Regression"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Calibration Curve</strong> for the Random Forest model reveals slight deviations from perfect calibration, particularly across the lower and mid-range probability values. The curve shows that the model tends to <strong>overestimate probabilities</strong> in certain bins (e.g., <strong>0.4–0.6</strong>) while underestimating in others, creating noticeable oscillations. At higher probability ranges (close to <strong>1.0</strong>), the model performs more reliably, aligning closely with the perfect calibration line. This indicates that the model’s confidence in high-probability predictions is well-placed, even if inconsistencies appear at lower thresholds. While the Random Forest model delivers strong classification performance overall, its probability estimates could benefit from additional calibration techniques to improve consistency and reliability across all probability ranges.</p>
</section>
</section>
<section id="k-nearest-neighbors-knn" class="level2">
<h2 class="anchored" data-anchor-id="k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</h2>
<section id="optimal-k" class="level4">
<h4 class="anchored" data-anchor-id="optimal-k">Optimal K</h4>
<div id="cell-58" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the range of 'n_neighbors' to test</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'n_neighbors'</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">31</span>)}  <span class="co"># Try k from 1 to 30</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the KNN model</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier()</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Use GridSearchCV to find the optimal n_neighbors</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(knn, param_grid, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>)  <span class="co"># 5-fold cross-validation</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best n_neighbors</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>best_n <span class="op">=</span> grid_search.best_params_[<span class="st">'n_neighbors'</span>]</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>best_score <span class="op">=</span> grid_search.best_score_</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal n_neighbors: </span><span class="sc">{</span>best_n<span class="sc">}</span><span class="ss">, Cross-Validation Accuracy: </span><span class="sc">{</span>best_score<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal n_neighbors: 6, Cross-Validation Accuracy: 0.88</code></pre>
</div>
</div>
<p>To optimize the performance of the <strong>K-Nearest Neighbors (KNN)</strong> model, the <strong>optimal value of ‘K’</strong> (number of neighbors) was determined using <strong>GridSearchCV</strong> with 5-fold cross-validation. A range of <code>K</code> values from <strong>1 to 30</strong> was tested to identify the parameter that maximizes model accuracy. The search identified an optimal <strong>K value of 6</strong>, achieving a <strong>cross-validation accuracy of 0.88</strong>. Choosing the appropriate ‘K’ is crucial for managing the trade-off between bias and variance: smaller <code>K</code> values can lead to overfitting, as the model becomes overly sensitive to noise, while larger values risk oversmoothing decision boundaries, causing the model to miss important patterns in the data. With the optimal <strong>K=6</strong>, the fine-tuned KNN model was finalized and evaluated on the test dataset, ensuring it strikes a balance between capturing patterns effectively and maintaining generalization.</p>
</section>
<section id="model-performance-summary-3" class="level3">
<h3 class="anchored" data-anchor-id="model-performance-summary-3">Model Performance Summary</h3>
<div id="cell-61" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># KNN Model</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>knn_model <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>best_n)  <span class="co"># Adjust n_neighbors as needed</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>knn_model.fit(X_train, y_train)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions and Probabilities</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>knn_y_pred <span class="op">=</span> knn_model.predict(X_test)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>knn_y_pred_proba <span class="op">=</span> knn_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation Metrics</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>knn_accuracy <span class="op">=</span> accuracy_score(y_test, knn_y_pred)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>knn_precision <span class="op">=</span> precision_score(y_test, knn_y_pred)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>knn_recall <span class="op">=</span> recall_score(y_test, knn_y_pred)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>knn_f1 <span class="op">=</span> f1_score(y_test, knn_y_pred)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>knn_roc_auc <span class="op">=</span> roc_auc_score(y_test, knn_y_pred_proba)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"KNN - Accuracy: </span><span class="sc">{</span>knn_accuracy<span class="sc">:.2f}</span><span class="ss">, Precision: </span><span class="sc">{</span>knn_precision<span class="sc">:.2f}</span><span class="ss">, Recall: </span><span class="sc">{</span>knn_recall<span class="sc">:.2f}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>knn_f1<span class="sc">:.2f}</span><span class="ss">, ROC-AUC: </span><span class="sc">{</span>knn_roc_auc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>KNN - Accuracy: 0.92, Precision: 0.91, Recall: 0.95, F1 Score: 0.93, ROC-AUC: 0.94</code></pre>
</div>
</div>
<p>The <strong>KNN model</strong> demonstrated excellent performance across all evaluation metrics:</p>
<ul>
<li><strong>Accuracy</strong>: 0.92 — The model correctly predicted 92% of the test set outcomes.<br>
</li>
<li><strong>Precision</strong>: 0.91 — 91% of predicted exonerated cases were correct.<br>
</li>
<li><strong>Recall</strong>: 0.95 — The model successfully identified 95% of actual exonerated individuals, minimizing false negatives.<br>
</li>
<li><strong>F1 Score</strong>: 0.93 — The harmonic mean of precision and recall reflects a strong balance between the two metrics.<br>
</li>
<li><strong>ROC-AUC</strong>: 0.94 — The model effectively distinguishes between exonerated and non-exonerated classes, with high discriminatory power.</li>
</ul>
<p>These results indicate that the KNN model, with an optimal <code>k</code> value of 6, provides a reliable classification of exoneration outcomes, outperforming several other models in overall accuracy and recall.</p>
</section>
<section id="roc-curve-3" class="level3">
<h3 class="anchored" data-anchor-id="roc-curve-3">ROC Curve</h3>
<div id="cell-64" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC Curve</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, knn_y_pred_proba)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="ss">f"KNN ROC Curve (AUC = </span><span class="sc">{</span>knn_roc_auc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"KNN ROC Curve"</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>ROC Curve</strong> rises sharply toward the top-left corner, indicating that the model effectively identifies exonerated cases while keeping false positives to a minimum. The <strong>AUC (Area Under the Curve)</strong> value of <strong>0.94</strong> further confirms the model’s strong discriminatory power. A high AUC score like this demonstrates that the KNN model reliably separates exonerated and non-exonerated individuals, even as the classification threshold varies. The curve’s steep ascent highlights the model’s ability to achieve high sensitivity early, capturing the majority of true positives while maintaining a low false positive rate. This strong performance underscores the KNN model’s effectiveness as a classifier, particularly with the optimized <strong><code>k = 6</code></strong>.</p>
</section>
<section id="confusion-matrix-3" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-3">Confusion Matrix</h3>
<div id="cell-67" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(knn_model, X_test, y_test)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix - KNN"</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Confusion Matrix</strong> for the K-Nearest Neighbors (KNN) model provides a clear breakdown of its performance on the test set:</p>
<ul>
<li><strong>True Negatives (Top-Left)</strong>: 96 cases were correctly classified as non-exonerated.<br>
</li>
<li><strong>False Positives (Top-Right)</strong>: 11 cases were incorrectly predicted as exonerated.<br>
</li>
<li><strong>False Negatives (Bottom-Left)</strong>: 6 cases were incorrectly classified as non-exonerated.<br>
</li>
<li><strong>True Positives (Bottom-Right)</strong>: 107 cases were correctly identified as exonerated.</li>
</ul>
<p>The KNN model delivers strong classification performance, correctly identifying the majority of instances in both classes. The <strong>false positive rate</strong> remains low, with only 11 misclassifications, while the <strong>false negative rate</strong> is minimal at just 6 cases. This balance aligns with the model’s <strong>high recall (0.95)</strong> and <strong>precision (0.91)</strong>, highlighting its effectiveness in capturing true positives while keeping errors to a minimum. The confusion matrix results reinforce the KNN model’s reliability, particularly its strength in accurately identifying exonerated individuals.</p>
</section>
<section id="calibration-curve-3" class="level3">
<h3 class="anchored" data-anchor-id="calibration-curve-3">Calibration Curve</h3>
<div id="cell-70" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calibration Curve</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>prob_true, prob_pred <span class="op">=</span> calibration_curve(y_test, knn_y_pred_proba, n_bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.plot(prob_pred, prob_true, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">"KNN"</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'gray'</span>, label<span class="op">=</span><span class="st">"Perfect Calibration"</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Mean Predicted Probability"</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Fraction of Positives"</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Calibration Curve - KNN"</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <strong>Calibration Curve</strong> for the K-Nearest Neighbors (KNN) model highlights varying degrees of calibration quality across different probability ranges:</p>
<ul>
<li>For <strong>lower predicted probabilities (0.0–0.4)</strong>, the model tends to <strong>underestimate</strong> the fraction of positives, indicating a conservative bias in these ranges.<br>
</li>
<li>At <strong>mid-range probabilities (0.6–0.8)</strong>, the predictions align closely with the perfect calibration line, suggesting reliable probability estimates in this range.<br>
</li>
<li>For <strong>higher predicted probabilities (0.8–1.0)</strong>, the model slightly <strong>overestimates</strong> the likelihood of positive outcomes, as seen in the upward deviation from the ideal line.</li>
</ul>
<p>While the KNN model demonstrates strong performance in predicting exoneration outcomes, the calibration curve indicates that probability estimates are less consistent at the extremes. Applying additional calibration techniques could improve reliability and provide more accurate confidence estimates across all probability ranges.</p>
</section>
</section>
<section id="model-comparison" class="level2">
<h2 class="anchored" data-anchor-id="model-comparison">Model Comparison</h2>
<div id="cell-73" class="cell" data-execution_count="186">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define metrics for each model</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>comparison_data <span class="op">=</span> {</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Metric"</span>: [<span class="st">"Accuracy"</span>, <span class="st">"Precision"</span>, <span class="st">"Recall"</span>, <span class="st">"F1 Score"</span>, <span class="st">"ROC-AUC"</span>],</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Logistic Regression"</span>: [log_accuracy, log_precision, log_recall, log_f1, log_roc_auc],</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Naive Bayes"</span>: [nb_accuracy, nb_precision, nb_recall, nb_f1, nb_roc_auc ],</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Random Forest"</span>: [rf_accuracy, rf_precision, rf_recall, rf_f1, rf_roc_auc],</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"K-Nearest Neighbors"</span>: [knn_accuracy, knn_precision, knn_recall, knn_f1, knn_roc_auc]</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the DataFrame</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>comparison_df <span class="op">=</span> pd.DataFrame(comparison_data)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Style the DataFrame for better readability</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>comparison_df.style.set_caption(<span class="st">"Model Comparison"</span>).highlight_max(axis<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">"lightgreen"</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the table</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>comparison_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="186">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Metric</th>
<th data-quarto-table-cell-role="th">Logistic Regression</th>
<th data-quarto-table-cell-role="th">Naive Bayes</th>
<th data-quarto-table-cell-role="th">Random Forest</th>
<th data-quarto-table-cell-role="th">K-Nearest Neighbors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Accuracy</td>
<td>0.895455</td>
<td>0.831818</td>
<td>0.909091</td>
<td>0.909091</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Precision</td>
<td>0.901786</td>
<td>0.756757</td>
<td>0.904348</td>
<td>0.872000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Recall</td>
<td>0.893805</td>
<td>0.991150</td>
<td>0.920354</td>
<td>0.964602</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>F1 Score</td>
<td>0.897778</td>
<td>0.858238</td>
<td>0.912281</td>
<td>0.915966</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ROC-AUC</td>
<td>0.952651</td>
<td>0.864403</td>
<td>0.954553</td>
<td>0.907535</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>To identify the best-performing model for predicting exoneration outcomes, four supervised learning algorithms — <strong>Logistic Regression</strong>, <strong>Naive Bayes</strong>, <strong>Random Forest</strong>, and <strong>K-Nearest Neighbors (KNN)</strong> — were evaluated across key performance metrics, including Accuracy, Precision, Recall, F1 Score, and ROC-AUC.</p>
<ul>
<li><strong>Logistic Regression</strong> delivered strong results with an <strong>accuracy of 0.89</strong> and an <strong>ROC-AUC of 0.95</strong>, showcasing excellent discriminatory power and reliable overall performance.<br>
</li>
<li><strong>Naive Bayes</strong> excelled in <strong>recall</strong>, achieving a score of <strong>0.99</strong> by capturing nearly all true positives. However, its <strong>lower precision (0.76)</strong> resulted in a higher false positive rate, reflecting a trade-off between sensitivity and precision.<br>
</li>
<li><strong>K-Nearest Neighbors (KNN)</strong> performed exceptionally well, with an <strong>accuracy of 0.91</strong>, <strong>recall of 0.96</strong>, and an <strong>ROC-AUC of 0.91</strong>, solidifying its reliability as a strong classifier despite a slight trade-off in precision.<br>
</li>
<li><strong>Random Forest</strong> emerged as the top-performing model, achieving the <strong>highest overall accuracy (0.91)</strong>, <strong>precision (0.94)</strong>, and <strong>F1 Score (0.91)</strong>, alongside a robust <strong>ROC-AUC of 0.95</strong>.</li>
</ul>
<p>Based on these results, <strong>Random Forest</strong> stands out as the most balanced and effective model, delivering superior performance across all critical evaluation metrics.</p>
<section id="why-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="why-random-forest">Why Random Forest?</h3>
<p>Random Forest was chosen as the final model due to its superior performance across all evaluation metrics. It delivered the highest accuracy and precision while maintaining strong recall, striking a balance between minimizing false positives and capturing true positives. The <strong>ROC-AUC score of 0.95</strong> highlights its exceptional ability to distinguish between exonerated and non-exonerated individuals. Additionally, Random Forest’s <strong>feature importance</strong> analysis provided valuable interpretability, identifying key predictors such as <strong>County_Cook</strong> and <strong>Race_Black</strong>. This combination of high performance, reliability, and interpretability makes Random Forest the most suitable model for predicting exoneration outcomes.</p>
<p>Random Forest’s outperformance can be attributed to its unique strengths as an <strong>ensemble method</strong>, which combines predictions from multiple decision trees to reduce overfitting and deliver consistent results across complex datasets. Specifically:</p>
<ol type="1">
<li><p><strong>Handling Non-Linearity</strong>: Unlike Logistic Regression, Random Forest does not rely on linear assumptions between features and the target variable, enabling it to capture more complex interactions within the data.</p></li>
<li><p><strong>Feature Importance</strong>: By leveraging all input features, Random Forest identifies the most influential predictors, improving both accuracy and interpretability, as demonstrated in the <strong>feature importance plot</strong>.</p></li>
<li><p><strong>Robustness to Noise and Outliers</strong>: Tree-based methods like Random Forest are inherently less sensitive to noisy data and outliers, which can significantly impact simpler models such as KNN or Naive Bayes.</p></li>
<li><p><strong>Balanced Bias-Variance Tradeoff</strong>: Averaging predictions across multiple trees allows Random Forest to reduce variance (overfitting) while maintaining low bias, ensuring strong generalization on unseen data.</p></li>
<li><p><strong>High Recall Without Sacrificing Precision</strong>: While Naive Bayes prioritized recall at the expense of precision, Random Forest effectively balances the two, capturing true positives while minimizing false positives.</p></li>
</ol>
<p>These strengths make Random Forest particularly well-suited for this dataset, where geographic and demographic factors interact in nuanced ways. Its ability to handle complex relationships, combined with its superior predictive power and interpretability, explains why it emerged as the best-performing model.</p>
</section>
</section>
</section>
<section id="predicted-probability-with-most-accurate-model" class="level1">
<h1>Predicted Probability with Most Accurate Model</h1>
<section id="average-predicted-probability-of-wrongful-conviction-in-illinois-by-race" class="level2">
<h2 class="anchored" data-anchor-id="average-predicted-probability-of-wrongful-conviction-in-illinois-by-race">Average Predicted Probability of Wrongful Conviction in Illinois by Race</h2>
<div id="cell-78" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities for the test set</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> rf_model.predict_proba(X_test)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The second column contains the probabilities for the positive class (Exonerated)</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>exoneration_probabilities <span class="op">=</span> probabilities[:, <span class="dv">1</span>]</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview the first few probabilities</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(exoneration_probabilities[:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.         0.         0.86253375 0.         1.         0.86253375
 0.         0.7507617  0.86253375 0.        ]</code></pre>
</div>
</div>
<div id="cell-79" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure X_test retains the one-hot encoded race columns</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>X_test_with_probabilities <span class="op">=</span> X_test.copy()  <span class="co"># Create a copy of X_test</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>X_test_with_probabilities[<span class="st">'exoneration_probability'</span>] <span class="op">=</span> exoneration_probabilities  <span class="co"># Add predicted probabilities</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Decode one-hot encoded race into a single column</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>race_columns <span class="op">=</span> [<span class="st">'Race_Black'</span>, <span class="st">'Race_Latino'</span>, <span class="st">'Race_Other'</span>, <span class="st">'Race_White'</span>]</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>X_test_with_probabilities[<span class="st">'Race'</span>] <span class="op">=</span> X_test_with_probabilities[race_columns].idxmax(axis<span class="op">=</span><span class="dv">1</span>).<span class="bu">str</span>.replace(<span class="st">'Race_'</span>, <span class="st">''</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Group by race and calculate average probabilities</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>race_probabilities <span class="op">=</span> X_test_with_probabilities.groupby(<span class="st">'Race'</span>)[<span class="st">'exoneration_probability'</span>].mean()</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> plt.cm.coolwarm(np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="bu">len</span>(race_probabilities)))</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> race_probabilities.sort_values().plot(kind<span class="op">=</span><span class="st">'bar'</span>, color<span class="op">=</span>colors, ax<span class="op">=</span>ax)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Average Predicted Probability of Wrongful Conviction by Race'</span>)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Race'</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Average Predicted Probability'</span>)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>ax.grid(axis<span class="op">=</span><span class="st">'y'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)  <span class="co"># Add horizontal grid lines for clarity</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the table of average probabilities</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>race_probabilities_df <span class="op">=</span> race_probabilities.reset_index()</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>race_probabilities_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display" data-execution_count="50">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Race</th>
<th data-quarto-table-cell-role="th">exoneration_probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Black</td>
<td>0.630754</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Latino</td>
<td>0.018190</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Other</td>
<td>0.030000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>White</td>
<td>0.178803</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The visualization reveals a stark disparity in the average predicted probability of wrongful conviction among incarcerated individuals in Illinois when analyzed by race. The model predicts that Black individuals face the highest average probability of being wrongfully convicted, at approximately <strong>63%</strong>. In contrast, White individuals show a significantly lower predicted probability of <strong>17.8%</strong>, while those categorized as <strong>“Other”</strong> and <strong>Latino</strong> have probabilities of <strong>3%</strong> and <strong>1.8%</strong>, respectively. These results reflect patterns the model identified within the dataset, which captures the exoneration outcomes of Illinois’ incarcerated population. The striking gap in predicted probabilities underscores the disproportionately higher likelihood of wrongful conviction for Black individuals—a concerning indication of racial inequities within the justice system. Meanwhile, the considerably lower probabilities for White, Latino, and Other groups further highlight the extent of this imbalance.</p>
</section>
<section id="average-predicted-probability-of-wrongful-conviction-in-illinois-by-county" class="level2">
<h2 class="anchored" data-anchor-id="average-predicted-probability-of-wrongful-conviction-in-illinois-by-county">Average Predicted Probability of Wrongful Conviction in Illinois by County</h2>
<div id="cell-82" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decode one-hot encoded county into a single column</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>county_columns <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> X_test.columns <span class="cf">if</span> col.startswith(<span class="st">'County_'</span>)]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> county_columns:</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    county_name <span class="op">=</span> col.replace(<span class="st">'County_'</span>, <span class="st">''</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    X_test_with_probabilities.loc[X_test_with_probabilities[col] <span class="op">==</span> <span class="dv">1</span>, <span class="st">'County'</span>] <span class="op">=</span> county_name</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Group by county and calculate average probabilities</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>county_probabilities <span class="op">=</span> X_test_with_probabilities.groupby(<span class="st">'County'</span>)[<span class="st">'exoneration_probability'</span>].mean()</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the average probabilities for each county using the coolwarm colormap</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">8</span>))</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>coolwarm_colors <span class="op">=</span> plt.cm.coolwarm(np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="bu">len</span>(county_probabilities)))</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> county_probabilities.sort_values().plot(</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    kind<span class="op">=</span><span class="st">'bar'</span>,</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span>coolwarm_colors,</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>ax</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Average Predicted Probability of Wrongful Conviction by County'</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'County'</span>)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Average Predicted Probability'</span>)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>ax.grid(axis<span class="op">=</span><span class="st">'y'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>) </span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the table of average probabilities</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>county_probabilities_df <span class="op">=</span> county_probabilities.reset_index()</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>county_probabilities_dict <span class="op">=</span> county_probabilities_df.set_index(<span class="st">'County'</span>)[<span class="st">'exoneration_probability'</span>].to_dict()</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Print each key-value pair</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> county, probability <span class="kw">in</span> county_probabilities_dict.items():</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>county<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>probability<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Bond: 0.0075
Brown: 0.0000
Champaign: 0.4724
Christian: 0.0406
Clinton: 0.0045
Cook: 0.8537
Cumberland: 0.0532
DuPage: 0.5765
Fayette: 0.0000
Fulton: 0.0000
Henry: 0.0244
Jefferson: 0.0205
Johnson: 0.0000
Kankakee: 0.4693
Knox: 0.0056
La Salle: 0.0090
Lawrence: 0.0519
Lee: 0.0071
Livingston: 0.1500
Logan: 0.0000
Macon: 0.3503
McHenry: 0.4854
Montgomery: 0.0000
Morgan: 0.0037
Moultrie: 0.0532
Peoria: 0.2247
Perry: 0.0000
Randolph: 0.0000
Rock Island: 0.0000
St. Clair: 0.1383
Stephenson: 0.0532
Tazewell: 0.0000
Vermilion: 0.1350
Will: 0.1541
Williamson: 0.2095
Winnebago: 0.2571
Woodford: 0.0856</code></pre>
</div>
</div>
<p><strong>Cook County</strong> emerges with the highest average predicted probability, exceeding <strong>80%</strong>. This result is particularly significant, as Cook County, which includes Chicago, represents the largest urban population in Illinois. The data suggests that wrongful convictions are disproportionately concentrated in over-policed, densely populated minority communities (as demonstrated by the EDA). Beyond Cook County, counties such as <strong>DuPage, McHenry, and Champaign</strong> also exhibit elevated predicted probabilities, reflecting a broader pattern of wrongful convictions in areas with similar over-policing dynamics. The overall findings underscore substantial geographic disparities in the predicted probability of wrongful convictions across Illinois. The sharp divide between counties like Cook and those with near-zero probabilities highlights systemic issues tied to over-policing, population density, and judicial or prosecutorial behavior in minority communities.</p>
</section>
<section id="average-predicted-probability-of-wrongful-conviction-in-illinois-by-race-and-ounty" class="level2">
<h2 class="anchored" data-anchor-id="average-predicted-probability-of-wrongful-conviction-in-illinois-by-race-and-ounty">Average Predicted Probability of Wrongful Conviction in Illinois by Race and ounty</h2>
<div id="cell-85" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Group by race and county, then calculate average probabilities</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>race_county_probabilities <span class="op">=</span> X_test_with_probabilities.groupby([<span class="st">'Race'</span>, <span class="st">'County'</span>])[<span class="st">'exoneration_probability'</span>].mean().unstack()</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot a heatmap for race vs. county</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">8</span>))  <span class="co"># Increase width for better visibility</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the heatmap</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    race_county_probabilities,  <span class="co"># Assuming this is your DataFrame</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    annot<span class="op">=</span><span class="va">True</span>,  <span class="co"># Display numerical values</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">".2f"</span>,  <span class="co"># Format the numbers to 2 decimal places</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"coolwarm"</span>,  <span class="co"># Use a diverging colormap</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    cbar<span class="op">=</span><span class="va">True</span>,  <span class="co"># Display color bar</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    linewidths<span class="op">=</span><span class="fl">0.5</span>  <span class="co"># Add spacing between cells</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Customize titles and labels</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Average Predicted Probability of Wrongful Conviction by Race and County"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"County"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Race"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Rotate x-axis ticks for better readability</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">30</span>, ha<span class="op">=</span><span class="st">"right"</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">12</span>)  <span class="co"># Increase font size for y-axis labels</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the heatmap</span></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  <span class="co"># Ensure everything fits within the figure</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The heatmap displays the <strong>average predicted probability of wrongful conviction</strong> across Illinois counties, broken down by race. The visualization highlights stark racial and geographic disparities, with Black individuals showing the highest predicted probabilities in several counties.</p>
<ul>
<li><p><strong>Cook County</strong> stands out prominently, with Black individuals exhibiting a predicted probability of <strong>0.89</strong>, the highest observed value across all groups. Similarly, counties such as <strong>Winnebago (0.77)</strong>, <strong>Clinton (0.47)</strong>, and <strong>Logan (0.48)</strong> report elevated probabilities for Black individuals, reinforcing patterns of wrongful convictions in over-policed, densely minority-populated areas.</p></li>
<li><p>For White individuals, the predicted probabilities are generally much lower but still notable in specific counties. <strong>Clinton County</strong> records a predicted probability of <strong>0.75</strong>, while <strong>Macon (0.49)</strong> and <strong>DuPage (0.50)</strong> also display higher-than-average values for this group. These exceptions, however, do not alter the overall trend: White individuals consistently show lower probabilities compared to Black individuals across most counties.</p></li>
<li><p>Latino and “Other” racial groups report significantly lower predicted probabilities across the state, with very few values exceeding <strong>0.17</strong>. Notably, the highest recorded probability for Latino individuals is in <strong>DuPage County (0.17)</strong>, while values for “Other” groups remain close to zero. These trends may reflect underrepresentation in the dataset rather than an absence of wrongful convictions.</p></li>
<li><p>Geographically, counties such as <strong>Cook, Winnebago, Clinton, and Logan</strong> emerge as key areas driving the racial disparities observed in the heatmap. The extreme values in counties like Cook underscore its disproportionate contribution to wrongful conviction probabilities, particularly for Black individuals. Meanwhile, counties with near-zero probabilities create a sharp contrast, suggesting regional or systemic factors at play.</p></li>
<li><p>Overall, the heatmap highlights the disproportionate burden of wrongful convictions on Black individuals across specific Illinois counties while showing significantly lower probabilities for White, Latino, and Other groups. These findings point to critical structural and systemic issues that require further investigation to address the racial and geographic disparities evident in the state’s criminal justice system.</p></li>
</ul>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The analysis of predicted probabilities of wrongful conviction by race and county reveals stark racial and geographic disparities among incarcerated individuals in Illinois, underscoring systemic inequities within the justice system. The results show that <strong>Black individuals</strong> face disproportionately higher risks of wrongful conviction, with an average predicted probability of <strong>63%</strong>, far surpassing that of White (<strong>17.8%</strong>), Latino (<strong>1.8%</strong>), and Other groups (<strong>3%</strong>). These disparities point to broader systemic issues, including racial profiling, over-policing in Black communities, and potential biases embedded within judicial processes.</p>
<p>Geographically, counties like <strong>Cook (0.89)</strong>, <strong>DuPage (0.75)</strong>, and <strong>Winnebago (0.77)</strong> exhibit the highest predicted probabilities for Black individuals, particularly Cook County, which emerges as the most significant contributor to statewide disparities. In contrast, smaller and less populated counties such as <strong>Montgomery</strong>, <strong>Brown</strong>, and <strong>Tazewell</strong> report near-zero probabilities, highlighting a geographic concentration of wrongful convictions in urban, over-policed, minority-populated regions. For White individuals, while overall probabilities remain lower, higher values are observed in counties like <strong>Clinton (0.75)</strong> and <strong>Macon (0.49)</strong>. Latino and Other racial groups consistently exhibit significantly lower probabilities across all counties, though this may reflect limited representation in the dataset rather than an absence of wrongful convictions.</p>
<p>These findings carry profound implications for reform. The disproportionately high predicted probabilities for Black individuals emphasize the urgent need to address racial bias in policing, prosecutorial practices, and judicial decision-making. Counties such as <strong>Cook</strong>, <strong>DuPage</strong>, and <strong>Winnebago</strong> require targeted policy interventions to investigate the underlying factors driving these outcomes, including resource imbalances, overloaded public defenders, and systemic prosecutorial pressures. Transparency, oversight, and equitable resource allocation are essential to addressing these systemic failures and ensuring fair outcomes across all racial and geographic lines. Ultimately, the analysis highlights the need for a systemic re-evaluation of policies and practices that contribute to the wrongful conviction burden, with a particular focus on mitigating its disproportionate impact on Black individuals in Illinois.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>